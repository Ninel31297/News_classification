{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Импорт библиотек"
      ],
      "metadata": {
        "id": "UEf5ko5mizp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFlaFbR5Xx9E",
        "outputId": "fcedc480-152e-4261-8571-f1224c7c6602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aiogram\n",
            "  Downloading aiogram-3.10.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting aiofiles~=23.2.1 (from aiogram)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: aiohttp~=3.9.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (3.9.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2024.7.4)\n",
            "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic<2.9,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.9.0->aiogram) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.9,>=2.4.1->aiogram) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.9,>=2.4.1->aiogram) (2.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp~=3.9.0->aiogram) (3.7)\n",
            "Downloading aiogram-3.10.0-py3-none-any.whl (570 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.6/570.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magic-filter, aiofiles, aiogram\n",
            "Successfully installed aiofiles-23.2.1 aiogram-3.10.0 magic-filter-1.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "from aiogram import (\n",
        "    Bot,\n",
        "    Dispatcher,\n",
        "    Router,\n",
        "    types,\n",
        ")\n",
        "from aiogram.filters import (\n",
        "    Command,\n",
        "    CommandStart,\n",
        ")\n",
        "from aiogram.types import BotCommand\n",
        "from aiogram.types.callback_query import CallbackQuery\n",
        "from aiogram.utils.keyboard import InlineKeyboardBuilder"
      ],
      "metadata": {
        "id": "lQPs2_VsqsPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Telegram bot\n",
        "\n",
        "Бот загружает заранеее подготовленные модели с диска\n",
        "\n",
        "Команды бота:\n",
        "\n",
        "`/start `- Вывести приветственное сообщение с описанием команд бота\n",
        "\n",
        "`/model` - Вывести список доступных моделей в виде кнопок. Доступные модели ('unigram', 'unigram_bigram', 'bigram', 'trigram')\n",
        "\n",
        "`/generate` - Отдать тэг для отправленной в бот новостной статьи\n",
        "\n",
        "`/checkmodel` - Вывести загруженную в данный момент модель\n",
        "\n",
        "`/help` - Вывести список доступных команд"
      ],
      "metadata": {
        "id": "UD1Ke4L-Jip7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationBot:\n",
        "\n",
        "    def __init__(self, token, models, vectorizers, encoder, supported_models):\n",
        "\n",
        "        self.token = token\n",
        "        self.bot = Bot(token)\n",
        "\n",
        "        self.dispatcher = Dispatcher() # Создаем диспетчер для обработки сообщений\n",
        "\n",
        "        # сохраняем модели, векторизаторы, кодировщик и поддерживаемые модели\n",
        "        self.models = models\n",
        "        self.vectorizers = vectorizers\n",
        "        self.encoder = encoder\n",
        "        self.supported_models = supported_models\n",
        "        self.active_model = supported_models[0] # По умолчанию активной моделью становится первая в списке\n",
        "\n",
        "    async def initialize_router(self):\n",
        "        # маршрутизатор\n",
        "        router = Router(name=\"classification\")\n",
        "\n",
        "        @router.message(CommandStart()) # Обработчик команды /start\n",
        "        async def start_handler(message: types.Message) -> None:\n",
        "\n",
        "            welcome_message = \"\"\"\n",
        "            Добро пожаловать!\n",
        "            Бот умеет подбирать топик для новостных статей.\n",
        "            ...\n",
        "            \"\"\"\n",
        "\n",
        "            if message.from_user:\n",
        "                await message.answer(\n",
        "                    textwrap.dedent(welcome_message),\n",
        "                )\n",
        "\n",
        "        @router.message(Command(\"model\")) # Обработчик команды /model\n",
        "        async def select_model(message: types.Message) -> None:\n",
        "\n",
        "            builder = InlineKeyboardBuilder()\n",
        "\n",
        "            for model in self.supported_models:\n",
        "                builder.row(\n",
        "                    types.InlineKeyboardButton(\n",
        "                        text=model,\n",
        "                        callback_data=model,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if message.from_user:\n",
        "                await message.answer(\n",
        "                    \"Выберите модель:\",\n",
        "                    reply_markup=builder.as_markup(\n",
        "                        resize_keyboard=True,\n",
        "                    ),\n",
        "                )\n",
        "\n",
        "        @router.callback_query() # Обработчик нажатий на клавиатуру для изменения модели\n",
        "        async def change_active_model(callback: CallbackQuery, bot: Bot) -> None:\n",
        "\n",
        "            self.active_model = callback.data\n",
        "\n",
        "            await callback.answer(\n",
        "                f\"Выбрана модель: {self.active_model}\",\n",
        "            )\n",
        "            await bot.delete_message(\n",
        "                chat_id=callback.message.chat.id,\n",
        "                message_id=callback.message.message_id,\n",
        "            )\n",
        "\n",
        "        @router.message(Command(\"checkmodel\")) # Обработчик команды /checkmodel\n",
        "        async def check_model(message: types.Message) -> None:\n",
        "\n",
        "            if message.from_user:\n",
        "                await message.answer(\n",
        "                    f\"Активная модель: {self.active_model}\",\n",
        "                )\n",
        "\n",
        "        @router.message(Command(\"generate\")) # Обработчик команды /generate\n",
        "        @router.message() # Обработчик всех сообщений бота\n",
        "        async def check_model(message: types.Message) -> None:\n",
        "\n",
        "            user_input = message.text.lstrip(\"/generate\") # Удаляем лишние пробелы\n",
        "\n",
        "            user_input = preprocess_text(user_input) # Обрабатываем текст\n",
        "\n",
        "            classifier = self.models[self.active_model] # Получаем модель\n",
        "            vectorizer = self.vectorizers[self.active_model] # Получаем векторизатор\n",
        "\n",
        "            test_features = vectorizer.transform([user_input]) # Преобразуем текст в вектор\n",
        "            predicted_label = classifier.predict(test_features) # Предсказываем класс\n",
        "\n",
        "            label = self.encoder.classes_[predicted_label] # Декодируем предсказанный класс\n",
        "\n",
        "            if message.from_user:\n",
        "                await message.answer(\n",
        "                    f\"Предсказанный топик: {label}\",\n",
        "                )\n",
        "\n",
        "        self.dispatcher.include_router(router=router) # Добавляем маршрутизатор в диспетчер\n",
        "\n",
        "    async def run(self): # Запуск бота\n",
        "        commands_dict: dict[str, str] = {\n",
        "            \"/start\": \"Начать работу с ботом\",\n",
        "            \"/model\": \"Выбрать модель\",\n",
        "            \"/checkmodel\": \"Вывести активную на даный момент модель\",\n",
        "            \"/generate\": \"Сгенерировать топик для новостной статьи\",\n",
        "        }\n",
        "\n",
        "        main_menu_commands = [\n",
        "            BotCommand(command=command, description=description)\n",
        "            for command, description in commands_dict.items()\n",
        "        ]\n",
        "\n",
        "        await self.bot.set_my_commands(main_menu_commands) # Устанавливаем команды для бота\n",
        "        await self.dispatcher.start_polling(self.bot) # Запускаем бота"
      ],
      "metadata": {
        "id": "_6ibgzI1JlKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Токен"
      ],
      "metadata": {
        "id": "HNu8GzACq8zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# вставить токен для тг бота\n",
        "TG_TOKEN = \"\""
      ],
      "metadata": {
        "id": "CRaUyM_AYwl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Загрузка моделей"
      ],
      "metadata": {
        "id": "W4HfJabwq-uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузим модели с диска\n",
        "test_classifiers, test_vectorizers, test_encoder = load_models()\n",
        "supported_models = ['unigram', 'unigram_bigram', 'bigram', 'trigram']"
      ],
      "metadata": {
        "id": "0UvsleAVYMyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Классификация"
      ],
      "metadata": {
        "id": "ayztPTgorBko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# инициализация бота\n",
        "bot = ClassificationBot(\n",
        "    TG_TOKEN,\n",
        "    test_classifiers,\n",
        "    test_vectorizers,\n",
        "    test_encoder,\n",
        "    supported_models,\n",
        ")\n",
        "\n",
        "await bot.initialize_router()\n",
        "await bot.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t9TvyNTX0bZ",
        "outputId": "cb2a99dd-aad5-488a-ef09-7bb7891ac1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ]
    }
  ]
}
